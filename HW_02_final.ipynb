{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_02",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omgW0dO8YBe9"
      },
      "source": [
        "### Домашнее задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVSLQnVwX-j3"
      },
      "source": [
        "1. Самостоятельно разобраться с тем, что такое tfidf (документация https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html и еще - https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)\n",
        "2. Модифицировать код функции get_user_embedding таким образом, чтобы считалось не среднее (как в примере np.mean), а медиана. Применить такое преобразование к данным, обучить модель прогнозирования оттока и посчитать метрики качества и сохранить их: roc auc, precision/recall/f_score (для 3 последних - подобрать оптимальный порог с помощью precision_recall_curve, как это делалось на уроке)\n",
        "3. Повторить п.2, но используя уже не медиану, а max\n",
        "4. (опциональное, если очень хочется) Воспользовавшись полученными знаниями из п.1, повторить пункт 2, но уже взвешивая новости по tfidf (подсказка: нужно получить веса-коэффициенты для каждого документа. Не все документы одинаково информативны и несут какой-то положительный сигнал). Подсказка 2 - нужен именно idf, как вес.\n",
        "5. Сформировать на выходе единую таблицу, сравнивающую качество 3 разных метода получения эмбедингов пользователей: mean, median, max, idf_mean по метрикам roc_auc, precision, recall, f_score\n",
        "6. Сделать самостоятельные выводы и предположения о том, почему тот или ной способ оказался эффективнее остальных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrpC2_A7ACmQ",
        "outputId": "dbcd2f2d-142f-411b-be58-9a7ba555e960"
      },
      "source": [
        "!pip install razdel"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting razdel\n",
            "  Downloading https://files.pythonhosted.org/packages/15/2c/664223a3924aa6e70479f7d37220b3a658765b9cfe760b4af7ffdc50d38f/razdel-0.5.0-py3-none-any.whl\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXKC4HjCAOTe",
        "outputId": "ba8b4ea1-9b50-41d9-d625-2cf6b616b1e5"
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 10.7MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUGsPZY_KZhM"
      },
      "source": [
        "from gensim.corpora.dictionary import Dictionary\n",
        "\n",
        "#предобработка текстов\n",
        "import re\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "#from nltk.tokenize import word_tokenize\n",
        "\n",
        "from razdel import tokenize # https://github.com/natasha/razdel\n",
        "#!pip install razdel\n",
        "\n",
        "import pymorphy2  \n",
        "# pip install pymorphy2\n",
        "\n",
        "import nltk"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO41d387WYWP"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q6wSZEcXhlm"
      },
      "source": [
        "import itertools\n",
        "import pandas as pd"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcwp-aQWAbkB"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqVaH-3NAPhQ",
        "outputId": "807d465f-bb93-4824-9602-ecfae441c7ed"
      },
      "source": [
        "# Загрузка файлов с гугл диска\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9cWTk-yHlBa",
        "outputId": "e15ad0ec-c043-4976-cc4d-693aa5538c25"
      },
      "source": [
        "!df -h"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         108G   39G   70G  36% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
            "shm             5.9G     0  5.9G   0% /dev/shm\n",
            "tmpfs           6.4G   36K  6.4G   1% /var/colab\n",
            "/dev/sda1        76G   41G   35G  55% /etc/hosts\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n",
            "drive           100G   35G   66G  35% /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l3ujUcqCc-D",
        "outputId": "d0cacacc-eae1-4bb9-9de5-cd9442ef006f"
      },
      "source": [
        "!ls /content/gdrive/MyDrive/Colab Notebooks/ML_in_business/les_02"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "articles.csv\t  HW_02\t\t users_articles.csv\n",
            "articles_idf.csv  stopwords.txt  users_churn.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw_6I4u1GhMl"
      },
      "source": [
        "!cp /content/gdrive/MyDrive/Colab Notebooks/ML_in_business/les_02/articles.csv ."
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va_y3uiGJQAd",
        "outputId": "964bd809-56d8-4467-ab8f-ab0bf6ad3bf6"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "articles.csv  gdrive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFISsLiSBIkO"
      },
      "source": [
        "news = pd.read_csv(\"articles.csv\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "0QYYkzhzOs2I",
        "outputId": "9a374ed7-2fad-4239-f5cb-be6cb6a0e0de"
      },
      "source": [
        "news.head(3)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>Заместитель председателяnправительства РФnСерг...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4896</td>\n",
              "      <td>Матч 1/16 финала Кубка России по футболу был п...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4897</td>\n",
              "      <td>Форвард «Авангарда» Томаш Заборский прокоммент...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   doc_id                                              title\n",
              "0       6  Заместитель председателяnправительства РФnСерг...\n",
              "1    4896  Матч 1/16 финала Кубка России по футболу был п...\n",
              "2    4897  Форвард «Авангарда» Томаш Заборский прокоммент..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-VNmcD-KQdx"
      },
      "source": [
        "!cp /content/gdrive/MyDrive/'Colab Notebooks'/ML_in_business/les_02/users_articles.csv ."
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "KDBdfQWLFI7A",
        "outputId": "571725f5-209b-4a94-8815-db1719749975"
      },
      "source": [
        "users = pd.read_csv(\"users_articles.csv\")\n",
        "users.head(3)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>articles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u105138</td>\n",
              "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u108690</td>\n",
              "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>u108339</td>\n",
              "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       uid                                        articles\n",
              "0  u105138  [293672, 293328, 293001, 293622, 293126, 1852]\n",
              "1  u108690          [3405, 1739, 2972, 1158, 1599, 322665]\n",
              "2  u108339          [1845, 2009, 2356, 1424, 2939, 323389]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKNGVSKtKiiH"
      },
      "source": [
        "### 1. Получаем векторные представления новостей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymyfTV-cKz6r",
        "outputId": "4c5fcca8-3e7d-477a-a584-efcda5c59e57"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe3V7ilpLCVj",
        "outputId": "ad7c3435-4656-4fe4-dfc9-3207e2b2c7ec"
      },
      "source": [
        "stopword_ru = stopwords.words('russian')\n",
        "print(len(stopword_ru))\n",
        "\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEEPD2q1LH8J",
        "outputId": "57b1f523-9cb3-4d19-bd6c-997419a9dd74"
      },
      "source": [
        "with open('/content/gdrive/MyDrive/Colab Notebooks/ML_in_business/les_02/stopwords.txt') as f:\n",
        "    additional_stopwords = [w.strip() for w in f.readlines() if w]\n",
        "stopword_ru += additional_stopwords\n",
        "len(stopword_ru)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "776"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WSqJqqK1Lgf2",
        "outputId": "50e50bc9-5bde-4592-f216-99c08e3e2b16"
      },
      "source": [
        "stopword_ru[-1]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'thru'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5NccgSzLjmZ"
      },
      "source": [
        "def clean_text(text):\n",
        "    '''\n",
        "    очистка текста\n",
        "    \n",
        "    на выходе очищеный текст\n",
        "    \n",
        "    '''\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    \n",
        "    text = text.lower()\n",
        "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
        "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
        "\n",
        "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
        "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
        "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
        "    text = re.sub(\"n\", ' ', text)\n",
        "\n",
        "    \n",
        "    #tokens = list(tokenize(text))\n",
        "    #words = [_.text for _ in tokens]\n",
        "    #words = [w for w in words if w not in stopword_ru]\n",
        "    \n",
        "    #return \" \".join(words)\n",
        "    return text\n",
        "\n",
        "cache = {}\n",
        "\n",
        "def lemmatization(text):\n",
        "    '''\n",
        "    лемматизация\n",
        "        [0] если зашел тип не `str` делаем его `str`\n",
        "        [1] токенизация предложения через razdel\n",
        "        [2] проверка есть ли в начале слова '-'\n",
        "        [3] проверка токена с одного символа\n",
        "        [4] проверка есть ли данное слово в кэше\n",
        "        [5] лемматизация слова\n",
        "        [6] проверка на стоп-слова\n",
        "\n",
        "    на выходе лист отлемматизированых токенов\n",
        "    '''\n",
        "\n",
        "    # [0]\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    \n",
        "    # [1]\n",
        "    tokens = list(tokenize(text))\n",
        "    #print(tokens)\n",
        "    words = [_.text for _ in tokens]\n",
        "\n",
        "    words_lem = []\n",
        "    for w in words:\n",
        "        if w[0] == '-': # [2]\n",
        "            w = w[1:]\n",
        "        if len(w)>1: # [3]\n",
        "            if w in cache: # [4]\n",
        "                words_lem.append(cache[w])\n",
        "                #print(temp_cach)\n",
        "            else: # [5]\n",
        "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
        "                words_lem.append(temp_cach)\n",
        "                #print(w,' : ',temp_cach)\n",
        "    \n",
        "    words_lem_without_stopwords=[i for i in words_lem if not i in stopword_ru] # [6]\n",
        "    #print(words_lem_without_stopwords)\n",
        "    return words_lem_without_stopwords"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoLzqcggLqqA",
        "outputId": "52fc1d7a-601f-4717-f6b1-b69f4f2935f4"
      },
      "source": [
        "list(tokenize(news.iloc[0,1][:100],   ))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0, 11, 'Заместитель'),\n",
              " Substring(12, 24, 'председателя'),\n",
              " Substring(24, 25, 'n'),\n",
              " Substring(25, 38, 'правительства'),\n",
              " Substring(39, 41, 'РФ'),\n",
              " Substring(41, 42, 'n'),\n",
              " Substring(42, 48, 'Сергей'),\n",
              " Substring(48, 49, 'n'),\n",
              " Substring(49, 55, 'Иванов'),\n",
              " Substring(55, 56, 'n'),\n",
              " Substring(56, 62, 'избран'),\n",
              " Substring(63, 76, 'председателем'),\n",
              " Substring(77, 83, 'совета'),\n",
              " Substring(83, 84, 'n'),\n",
              " Substring(84, 87, 'ПБК'),\n",
              " Substring(88, 92, 'ЦСКА'),\n",
              " Substring(92, 93, 'n'),\n",
              " Substring(93, 94, '.'),\n",
              " Substring(95, 98, 'Как'),\n",
              " Substring(99, 100, 'с')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EREpERS1M6Yq",
        "outputId": "e66dba5b-ff93-4b94-b81c-32faf3d55822"
      },
      "source": [
        "norm_text = news.iloc[:2,1].apply(lambda x: clean_text(x), 1)\n",
        "norm_text"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: FutureWarning: Possible nested set at position 39\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    заместитель председателя правительства рф серг...\n",
              "1    матч  финала кубка россии по футболу был приос...\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsD-Khl9NixG"
      },
      "source": [
        "#lemmatization(norm_text[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3XRDUhTNtnL",
        "outputId": "8782498a-cf1e-45bc-c51b-ec53f0e04f56"
      },
      "source": [
        "%%time\n",
        "#Запускаем очистку текста. Будет долго...\n",
        "news['title'] = news['title'].apply(lambda x: clean_text(x), 1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 26.3 s, sys: 1.68 s, total: 27.9 s\n",
            "Wall time: 28 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCa_fjO2NzRC",
        "outputId": "69f8b818-1242-4fc0-80bd-f93a08e2a537"
      },
      "source": [
        "%%time\n",
        "#Запускаем лемматизацию текста. Будет очень долго...\n",
        "news['title'] = news['title'].apply(lambda x: lemmatization(x), 1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4min 13s, sys: 425 ms, total: 4min 13s\n",
            "Wall time: 4min 14s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMcGZb-iOgAR"
      },
      "source": [
        "А теперь в 3 строчки обучим нашу модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOqhF0_POdsV"
      },
      "source": [
        "#сформируем список наших текстов, разбив еще и на пробелы\n",
        "texts = [t for t in news['title'].values]\n",
        "\n",
        "# Create a corpus from a list of texts\n",
        "common_dictionary = Dictionary(texts)\n",
        "common_corpus = [common_dictionary.doc2bow(text) for text in texts]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my8x6woBPSAJ"
      },
      "source": [
        "N_topic = 30 # число тем - гиперпараметр"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBoNku15OJj3"
      },
      "source": [
        "# todo не забыть поменять количество тем"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tRLsrqEPgzS",
        "outputId": "814a325f-87d6-4b69-a7fd-0acc90bf31ab"
      },
      "source": [
        "%%time\n",
        "from gensim.models import LdaModel\n",
        "# Train the model on the corpus.\n",
        "lda = LdaModel(common_corpus, num_topics=N_topic, id2word=common_dictionary)#, passes=10)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 58.4 s, sys: 29.4 s, total: 1min 27s\n",
            "Wall time: 55.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P61txbjDPzpR"
      },
      "source": [
        "from gensim.test.utils import datapath\n",
        "# Save model to disk.\n",
        "temp_file = datapath(\"model.lda\")\n",
        "lda.save(temp_file)\n",
        "\n",
        "# Load a potentially pretrained model from disk.\n",
        "lda = LdaModel.load(temp_file)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoaL4xFaQRFP"
      },
      "source": [
        "def get_lda_vector(text):\n",
        "    unseen_doc = common_dictionary.doc2bow(text)\n",
        "    lda_tuple = lda[unseen_doc]\n",
        "    not_null_topics = dict(zip([i[0] for i in lda_tuple], [i[1] for i in lda_tuple]))\n",
        "\n",
        "    output_vector = []\n",
        "    for i in range(N_topic):\n",
        "        if i not in not_null_topics:\n",
        "            output_vector.append(0)\n",
        "        else:\n",
        "            output_vector.append(not_null_topics[i])\n",
        "    return np.array(output_vector)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "FGP7NY_DUNnT",
        "outputId": "b0f304b4-d001-4ab3-fdf8-a2b43c6c7f57"
      },
      "source": [
        "topic_matrix = pd.DataFrame([get_lda_vector(text) for text in news['title'].values])\n",
        "topic_matrix.columns = ['topic_{}'.format(i) for i in range(N_topic)]\n",
        "topic_matrix['doc_id'] = news['doc_id'].values\n",
        "topic_matrix = topic_matrix[['doc_id']+['topic_{}'.format(i) for i in range(N_topic)]]\n",
        "topic_matrix.head(5)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>topic_0</th>\n",
              "      <th>topic_1</th>\n",
              "      <th>topic_2</th>\n",
              "      <th>topic_3</th>\n",
              "      <th>topic_4</th>\n",
              "      <th>topic_5</th>\n",
              "      <th>topic_6</th>\n",
              "      <th>topic_7</th>\n",
              "      <th>topic_8</th>\n",
              "      <th>topic_9</th>\n",
              "      <th>topic_10</th>\n",
              "      <th>topic_11</th>\n",
              "      <th>topic_12</th>\n",
              "      <th>topic_13</th>\n",
              "      <th>topic_14</th>\n",
              "      <th>topic_15</th>\n",
              "      <th>topic_16</th>\n",
              "      <th>topic_17</th>\n",
              "      <th>topic_18</th>\n",
              "      <th>topic_19</th>\n",
              "      <th>topic_20</th>\n",
              "      <th>topic_21</th>\n",
              "      <th>topic_22</th>\n",
              "      <th>topic_23</th>\n",
              "      <th>topic_24</th>\n",
              "      <th>topic_25</th>\n",
              "      <th>topic_26</th>\n",
              "      <th>topic_27</th>\n",
              "      <th>topic_28</th>\n",
              "      <th>topic_29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>0.079679</td>\n",
              "      <td>0.044562</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151755</td>\n",
              "      <td>0.014016</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.116619</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.360513</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.078800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.132336</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01558</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4896</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.570644</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.406592</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4897</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.330829</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.402190</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.205148</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4898</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047681</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.409230</td>\n",
              "      <td>0.033312</td>\n",
              "      <td>0.028951</td>\n",
              "      <td>0.013223</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.438227</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020025</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4899</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250674</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030061</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.084644</td>\n",
              "      <td>0.449656</td>\n",
              "      <td>0.162442</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   doc_id   topic_0   topic_1  topic_2  ...  topic_26  topic_27  topic_28  topic_29\n",
              "0       6  0.079679  0.044562      0.0  ...  0.000000       0.0       0.0       0.0\n",
              "1    4896  0.000000  0.000000      0.0  ...  0.000000       0.0       0.0       0.0\n",
              "2    4897  0.000000  0.000000      0.0  ...  0.205148       0.0       0.0       0.0\n",
              "3    4898  0.000000  0.047681      0.0  ...  0.000000       0.0       0.0       0.0\n",
              "4    4899  0.000000  0.000000      0.0  ...  0.000000       0.0       0.0       0.0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIa_M3UxUb4j"
      },
      "source": [
        "### Следующий шаг - векторные представления пользователей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "rVEsAvkuUTch",
        "outputId": "55a89a63-d53f-4e31-d3ea-958848e0f130"
      },
      "source": [
        "users.head(10)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>articles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u105138</td>\n",
              "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u108690</td>\n",
              "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>u108339</td>\n",
              "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>u101138</td>\n",
              "      <td>[5933, 6186, 5055, 6977, 5206, 488389]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>u108248</td>\n",
              "      <td>[707, 1144, 2532, 2928, 3133, 324592]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>u106662</td>\n",
              "      <td>[323868, 323426, 324267, 322426, 324104, 1550]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>u105949</td>\n",
              "      <td>[293138, 294471, 295012, 294736, 293949, 3544]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>u102457</td>\n",
              "      <td>[6928, 5009, 6940, 7629, 7644, 512736]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>u104124</td>\n",
              "      <td>[322838, 324699, 322991, 322120, 324327, 472331]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>u101386</td>\n",
              "      <td>[7827, 6427, 7394, 7151, 6335, 487254]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       uid                                          articles\n",
              "0  u105138    [293672, 293328, 293001, 293622, 293126, 1852]\n",
              "1  u108690            [3405, 1739, 2972, 1158, 1599, 322665]\n",
              "2  u108339            [1845, 2009, 2356, 1424, 2939, 323389]\n",
              "3  u101138            [5933, 6186, 5055, 6977, 5206, 488389]\n",
              "4  u108248             [707, 1144, 2532, 2928, 3133, 324592]\n",
              "5  u106662    [323868, 323426, 324267, 322426, 324104, 1550]\n",
              "6  u105949    [293138, 294471, 295012, 294736, 293949, 3544]\n",
              "7  u102457            [6928, 5009, 6940, 7629, 7644, 512736]\n",
              "8  u104124  [322838, 324699, 322991, 322120, 324327, 472331]\n",
              "9  u101386            [7827, 6427, 7394, 7151, 6335, 487254]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygK9CCNCV1DJ"
      },
      "source": [
        "doc_dict = dict(zip(topic_matrix['doc_id'].values, topic_matrix[['topic_{}'.format(i) for i in range(N_topic)]].values))"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08Bcgk2zx1r5"
      },
      "source": [
        "def get_user_embedding(user_articles_list, metric = np.max): # mean, median, max \n",
        "    user_articles_list = eval(user_articles_list)\n",
        "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
        "    #print(user_vector)\n",
        "    user_vector = metric(user_vector, 0)\n",
        "    return user_vector"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "h1_fsdbcWC9B",
        "outputId": "f364fe2f-f2e6-4ea8-c184-b49c29d8adbc"
      },
      "source": [
        "target = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/ML_in_business/les_02/users_churn.csv\")\n",
        "target.head(3)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u107120</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u102277</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>u102444</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       uid  churn\n",
              "0  u107120      0\n",
              "1  u102277      0\n",
              "2  u102444      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyt2Zr_qqkl"
      },
      "source": [
        "def get_preds (emb_metric):\n",
        "\n",
        "    user_embeddings = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding(x, emb_metric), 1)])\n",
        "    user_embeddings.columns = ['topic_{}'.format(i) for i in range(N_topic)]\n",
        "    user_embeddings['uid'] = users['uid'].values\n",
        "    user_embeddings = user_embeddings[['uid']+['topic_{}'.format(i) for i in range(N_topic)]]\n",
        "    user_embeddings.head(3)\n",
        "\n",
        "    X = pd.merge(user_embeddings, target, 'left')\n",
        "    #разделим данные на train/test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X[['topic_{}'.format(i) for i in range(N_topic)]], \n",
        "                                                    X['churn'], random_state=0, test_size=0.25)\n",
        "    logreg = LogisticRegression(C=1.0)\n",
        "    #обучим логистич модель\n",
        "    logreg.fit(X_train, y_train)\n",
        "    #наши прогнозы для тестовой выборки\n",
        "    preds = logreg.predict_proba(X_test)[:, 1]\n",
        "    return preds"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qi6dwgZsc_A"
      },
      "source": [
        "preds_max = get_preds (np.max)\n",
        "preds_mean = get_preds (np.mean)\n",
        "preds_median = get_preds (np.median)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuDz70uuWxsN"
      },
      "source": [
        "### Рассчитаем Precision, Recall, F_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btDYLWNHWzXB"
      },
      "source": [
        "def calc_metrics(y_test, preds):\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
        "    fscore = (2 * precision * recall) / (precision + recall)\n",
        "    \n",
        "    # locate the index of the largest f score\n",
        "    ix = np.argmax(fscore)\n",
        "    roc_auc = roc_auc_score(y_test, preds)\n",
        "    return thresholds[ix], fscore[ix], precision[ix], recall[ix], roc_auc"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GljRzJ6vc7t"
      },
      "source": [
        "preds = [preds_max, preds_mean, preds_median]\n",
        "metrics = []\n",
        "\n",
        "for p in preds:\n",
        "    threshold, fscore, precision, recall, roc_auc = calc_metrics(y_test, p)\n",
        "    metrics.append([threshold, fscore, precision, recall, roc_auc])"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "1EKGPqx8ve9I",
        "outputId": "8d84a545-e993-44f4-cfff-b867391813dc"
      },
      "source": [
        "metrics_df = pd.DataFrame(metrics,\n",
        "                          columns = ['threshold', 'f-score', 'precision', 'recall', 'roc_auc'],\n",
        "                          index = ['preds_max', 'preds_mean', 'preds_median'])\n",
        "metrics_df"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>f-score</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>preds_max</th>\n",
              "      <td>0.371032</td>\n",
              "      <td>0.836066</td>\n",
              "      <td>0.839506</td>\n",
              "      <td>0.832653</td>\n",
              "      <td>0.982041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>preds_mean</th>\n",
              "      <td>0.261842</td>\n",
              "      <td>0.711281</td>\n",
              "      <td>0.669065</td>\n",
              "      <td>0.759184</td>\n",
              "      <td>0.955630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>preds_median</th>\n",
              "      <td>0.219732</td>\n",
              "      <td>0.706897</td>\n",
              "      <td>0.611940</td>\n",
              "      <td>0.836735</td>\n",
              "      <td>0.955983</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              threshold   f-score  precision    recall   roc_auc\n",
              "preds_max      0.371032  0.836066   0.839506  0.832653  0.982041\n",
              "preds_mean     0.261842  0.711281   0.669065  0.759184  0.955630\n",
              "preds_median   0.219732  0.706897   0.611940  0.836735  0.955983"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vk05XPB5ira"
      },
      "source": [
        "# 20 тем\n",
        "\t        #threshold\tf-score\tprecision\trecall\troc_auc\n",
        "#preds_max\t0.361413\t0.702703\t0.716102\t0.689796\t0.950316\n",
        "#preds_mean\t0.278266\t0.652591\t0.615942\t0.693878\t0.939422\n",
        "#preds_median\t0.273866\t0.762082\t0.699659\t0.836735\t0.968242"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7hCISftaiGH"
      },
      "source": [
        "С увеличением количества тем с 10 до 20 показатели зничительно улучшились, например, roc_auc_ с 0.79 до 0.95"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txJzSi-Y47fA"
      },
      "source": [
        "При количестве тем = 20 медиана сработала лучше, вероятно потому, что она более устойчива к выбросам, возможно, какие-то темы с большой вероятностью были выбраны ошибочно, а темы со средней вероятностью лучше характеризуют пользователя"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN-8YMVl7OVh"
      },
      "source": [
        " # 30 тем\n",
        " #           threshold\tf-score\tprecision\trecall\troc_auc\n",
        "#preds_max\t0.371032\t0.836066\t0.839506\t0.832653\t0.982041\n",
        "#preds_mean\t0.261842\t0.711281\t0.669065\t0.759184\t0.955630\n",
        "#preds_median\t0.219732\t0.706897\t0.611940\t0.836735\t0.955983"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOOg4mh87DTh"
      },
      "source": [
        "Но при увеличении количества тем до 30, лучшие показатели получились у максимальной темы. видимо, при увеличении кол-ва тем получается более точное попадание в темы, и хорошо срабатывает max, причем по всем метрикам.\n",
        "\n",
        "Подскажите, будет ли выложено решение, как сделать взвешивая новости по tfidf? Хотелось бы посмотреть."
      ]
    }
  ]
}